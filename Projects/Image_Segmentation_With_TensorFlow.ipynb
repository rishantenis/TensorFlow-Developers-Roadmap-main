{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6O-VjxjVaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def create_mask(image_size, bbox):\n",
        "\n",
        "    mask = np.zeros(image_size, dtype=np.uint8)\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    mask[y_min:y_max, x_min:x_max] = 1\n",
        "    return mask\n",
        "\n",
        "# Example usage:\n",
        "image_size = (100, 100) # replace with your image size\n",
        "bbox = (10, 20, 30, 40) # replace with your bounding box coordinates\n",
        "mask = create_mask(image_size, bbox)\n",
        "\n",
        "# Convert to a TensorFlow tensor\n",
        "mask_tensor = tf.convert_to_tensor(mask, dtype=tf.uint8)\n",
        "\n",
        "# Optionally, save the mask as an image for visualization\n",
        "mask_image = Image.fromarray(mask * 255) # multiply by 255 to make the mask visible\n",
        "mask_image.save('mask.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "\n",
        "# Load a pre-trained object detection model from TensorFlow Hub\n",
        "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\")\n",
        "\n",
        "# Define the function\n",
        "def object_detection_and_masking_function(image):\n",
        "    # Convert the image to a tensor and add a batch dimension\n",
        "    image_tensor = tf.convert_to_tensor(image)\n",
        "    image_tensor = image_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # Perform detection\n",
        "    detector_output = detector(image_tensor)\n",
        "\n",
        "    # Process the output to extract bounding boxes and class labels\n",
        "    detection_boxes = detector_output['detection_boxes'][0].numpy()\n",
        "    detection_scores = detector_output['detection_scores'][0].numpy()\n",
        "    detection_classes = detector_output['detection_classes'][0].numpy()\n",
        "\n",
        "    # Confidence threshold for detection\n",
        "    confidence_threshold = 0.5\n",
        "\n",
        "    # List to hold masks and annotations\n",
        "    masks = []\n",
        "    annotations = []\n",
        "\n",
        "    # Go through the detections and create masks for high confidence detections\n",
        "    for i in range(detection_boxes.shape[0]):\n",
        "        if detection_scores[i] > confidence_threshold:\n",
        "            # Get the bounding box coordinates\n",
        "            y_min, x_min, y_max, x_max = detection_boxes[i]\n",
        "            y_min, x_min, y_max, x_max = int(y_min * image.shape[0]), int(x_min * image.shape[1]), \\\n",
        "                                          int(y_max * image.shape[0]), int(x_max * image.shape[1])\n",
        "\n",
        "            # Create a mask for the bounding box\n",
        "            # Note that this is a simple binary mask for a rectangle\n",
        "            mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "            mask[y_min:y_max, x_min:x_max] = 1\n",
        "\n",
        "            # Append to lists\n",
        "            masks.append(mask)\n",
        "            annotations.append({\n",
        "                'box': [x_min, y_min, x_max, y_max],\n",
        "                'class': detection_classes[i],\n",
        "                'score': detection_scores[i]\n",
        "            })\n",
        "\n",
        "    return masks, annotations\n",
        "\n",
        "# To use this function, pass an image as a numpy array:\n",
        "#image_np = np.array(Image.open('/content/Unknown.jpeg'))\n",
        "#masks, annotations = object_detection_and_masking_function(image_np)\n"
      ],
      "metadata": {
        "id": "x_RYAV0HYoOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an image\n",
        "image_path = '/content/Unknown2.jpeg'\n",
        "image_np = np.array(Image.open(image_path))\n",
        "\n",
        "# Get masks and annotations\n",
        "masks, annotations = object_detection_and_masking_function(image_np)\n",
        "\n",
        "# Function to display images, masks, and annotations\n",
        "def display_images_masks_annotations(image, masks, annotations):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title('Original Image\\nCredit: Bytes of Intelligence')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(masks[0], cmap='jet', alpha=0.5)  # Change masks[0] to iterate over all masks if multiple objects are detected\n",
        "    plt.title('Image with Mask\\nCredit: Bytes of Intelligence')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    for annotation in annotations:\n",
        "        x_min, y_min, x_max, y_max = annotation['box']\n",
        "        plt.plot([x_min, x_min, x_max, x_max, x_min], [y_min, y_max, y_max, y_min, y_min], 'r-')\n",
        "    plt.imshow(image)\n",
        "    plt.title('Image with Bounding Boxes\\nCredit: Bytes of Intelligence')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Display the results\n",
        "display_images_masks_annotations(image_np, masks, annotations)\n"
      ],
      "metadata": {
        "id": "i8j0AKuiZ6s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_object_detection_and_masking_function(images, model, threshold=0.5):\n",
        "    # Stack images into one large batch\n",
        "    batched_images = tf.stack(images, axis=0)\n",
        "\n",
        "    # Perform detection on the entire batch\n",
        "    detector_output = model(batched_images)\n",
        "\n",
        "    # Initialize lists to hold the masks and annotations for each image\n",
        "    batch_masks = []\n",
        "    batch_annotations = []\n",
        "\n",
        "    # Iterate over each image in the batch\n",
        "    for i in range(batched_images.shape[0]):\n",
        "        # Process the output to extract bounding boxes and class labels\n",
        "        detection_boxes = detector_output['detection_boxes'][i].numpy()\n",
        "        detection_scores = detector_output['detection_scores'][i].numpy()\n",
        "        detection_classes = detector_output['detection_classes'][i].numpy()\n",
        "\n",
        "        # Lists to hold masks and annotations for the current image\n",
        "        masks = []\n",
        "        annotations = []\n",
        "\n",
        "        # Go through the detections and create masks for high confidence detections\n",
        "        for j in range(detection_boxes.shape[0]):\n",
        "            if detection_scores[j] > threshold:\n",
        "                # Get the bounding box coordinates\n",
        "                y_min, x_min, y_max, x_max = detection_boxes[j]\n",
        "                y_min, x_min, y_max, x_max = int(y_min * images[i].shape[0]), int(x_min * images[i].shape[1]), \\\n",
        "                                              int(y_max * images[i].shape[0]), int(x_max * images[i].shape[1])\n",
        "\n",
        "                # Create a mask for the bounding box\n",
        "                mask = np.zeros(images[i].shape[:2], dtype=np.uint8)\n",
        "                mask[y_min:y_max, x_min:x_max] = 1\n",
        "\n",
        "                # Append to lists\n",
        "                masks.append(mask)\n",
        "                annotations.append({\n",
        "                    'box': [x_min, y_min, x_max, y_max],\n",
        "                    'class': detection_classes[j],\n",
        "                    'score': detection_scores[j]\n",
        "                })\n",
        "\n",
        "        # Append masks and annotations for the current image to the batch lists\n",
        "        batch_masks.append(masks)\n",
        "        batch_annotations.append(annotations)\n",
        "\n",
        "    return batch_masks, batch_annotations\n"
      ],
      "metadata": {
        "id": "J9New1xxV3Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the pre-trained object detection model from TensorFlow Hub\n",
        "model_url = \"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\"\n",
        "model = hub.load(model_url)\n",
        "\n",
        "# List of image paths\n",
        "image_paths = ['/content/Unknown2.jpeg']\n",
        "\n",
        "# The expected input size for the SSD MobileNet V2 model is 320x320\n",
        "input_size = (320, 320)\n",
        "\n",
        "# Initialize the list to hold the preprocessed images\n",
        "images = []\n",
        "\n",
        "for img_path in image_paths:\n",
        "    # Load the image\n",
        "    img = load_img(img_path, target_size=input_size)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    # Convert the image array to uint8\n",
        "    img_array = np.uint8(img_array)\n",
        "\n",
        "    # Append the processed image tensor to our list\n",
        "    images.append(img_array)\n",
        "\n",
        "# Convert the list of images to a batched tensor with the correct dtype\n",
        "image_tensors = tf.convert_to_tensor(images, dtype=tf.uint8)\n",
        "\n",
        "# Your object detection and masking function here...\n",
        "\n",
        "# Get masks and annotations for the batch\n",
        "batch_masks, batch_annotations = batch_object_detection_and_masking_function(image_tensors, model)\n"
      ],
      "metadata": {
        "id": "KJqli_sRdfBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_detections(image, masks, annotations):\n",
        "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Draw each mask\n",
        "    for mask in masks:\n",
        "        masked_image = np.ma.masked_where(mask == 0, mask)\n",
        "        ax.imshow(masked_image, 'jet', alpha=0.5)\n",
        "\n",
        "    # Draw each bounding box\n",
        "    for annotation in annotations:\n",
        "        x_min, y_min, x_max, y_max = annotation['box']\n",
        "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n",
        "                                 linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have at least one image in your batch\n",
        "visualize_image = images[0]  # First image of the batch\n",
        "visualize_masks = batch_masks[0]  # Masks for the first image\n",
        "visualize_annotations = batch_annotations[0]  # Annotations for the first image\n",
        "\n",
        "# Visualize the detections for the first image\n",
        "visualize_detections(visualize_image, visualize_masks, visualize_annotations)\n"
      ],
      "metadata": {
        "id": "RPuhCmgzWSUS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}